{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aO-7t1Y7-hV4"
   },
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "wePdX3_qnaPX",
    "outputId": "7b8862a1-3bbd-4532-9fb7-d7c93422872d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model execution started at:Sun May 24 17:30:03 2020\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print(\"Model execution started at:\" + datetime.datetime.today().ctime())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8kH16rnZ7wt_"
   },
   "outputs": [],
   "source": [
    "from src.dataset.monocularhelper import MonocularHelper\n",
    "from src.imports import *\n",
    "import torch.optim.lr_scheduler\n",
    "import os\n",
    "# from src.train.torchvision import collate_fn, train_one_epoch, warmup_lr_scheduler, MetricLogger, SmoothedValue\n",
    "\n",
    "%config IPCompleter.greedy=True\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_CINBFLZ6vmn"
   },
   "outputs": [],
   "source": [
    "%autoreload 2  # Autoreload all modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "Y4pGGPo0H7QM",
    "outputId": "686f9704-9684-48ac-c26a-0cf1b6b15d2e"
   },
   "outputs": [],
   "source": [
    "# def printgpuinfo():\n",
    "#     gpu_info = !nvidia-smi\n",
    "#     gpu_info = '\\n'.join(gpu_info)\n",
    "#     if gpu_info.find('failed') >= 0:\n",
    "#       print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n",
    "#       print('and then re-execute this cell.')\n",
    "#     else:\n",
    "#       print(gpu_info)\n",
    "    \n",
    "# printgpuinfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 119
    },
    "colab_type": "code",
    "id": "aqLk2ZwYH9PQ",
    "outputId": "ecfe93ea-7e58-4e57-8954-04e1f73ca5d3"
   },
   "outputs": [],
   "source": [
    "# def showsysteminfo():\n",
    "#     from psutil import virtual_memory\n",
    "#     ram_gb = virtual_memory().total / 1e9\n",
    "#     ram_gb_avail = virtual_memory().available / 1e9\n",
    "#     ram_gb_used = virtual_memory().active / 1e9\n",
    "#     print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
    "#     print('Your runtime has {:.1f} gigabytes of free RAM\\n'.format(ram_gb_avail))\n",
    "#     print('Your runtime has {:.1f} gigabytes of used RAM\\n'.format(ram_gb_used))    \n",
    "# showsysteminfo()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0k-00HKfnaPs",
    "outputId": "1f33be0b-c119-42c6-8554-6e0b7607841d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 744
    },
    "colab_type": "code",
    "id": "7ZuuPkUbnaPw",
    "outputId": "1fd85004-a629-43ed-df46-00ec26c668a0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 40/40 [00:11<00:00,  3.58it/s]\n"
     ]
    }
   ],
   "source": [
    "helper = MonocularHelper()\n",
    "# final_output = r'/media/abhijit/DATA/Development/TSAI/EVA/MaskRCNN Dataset/OverLayedImages'\n",
    "# final_output_mask = r'/media/abhijit/DATA/Development/TSAI/EVA/MaskRCNN Dataset/OverLayedMask'\n",
    "# final_output_dm = r'/media/abhijit/DATA/Development/TSAI/EVA/MaskRCNN Dataset/OverLayedDepthMasks'\n",
    "# bg_path = r'/media/abhijit/DATA/Development/TSAI/EVA/MaskRCNN Dataset/Background'\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "final_output = r'C:\\MonocularDS\\OverLayedImages'\n",
    "final_output_mask = r'C:\\MonocularDS\\OverLayedMask'\n",
    "final_output_dm = r'C:\\MonocularDS\\OverLayedDepthMasks'\n",
    "bg_path = r'C:\\MonocularDS\\Background'\n",
    "\n",
    "train_data, train_label, test_data, test_label = helper.get_train_test_data(masks_folder=final_output_mask,\n",
    "                                                                            images_folder=final_output,\n",
    "                                                                            depth_masks_folder=final_output_dm,\n",
    "                                                                            no_of_batches=40,\n",
    "                                                                            total_images_count=400000,\n",
    "                                                                            bg_folder=bg_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 491
    },
    "colab_type": "code",
    "id": "hWZPPo3yEHDW",
    "outputId": "dc455d25-a1b9-4b97-d1cb-bbdc6c38399d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "280000\n",
      "120000\n",
      "CUDA Available? True\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(train_label))\n",
    "print(len(test_label))\n",
    "\n",
    "batch_size = 8\n",
    "image_size = 32\n",
    "\n",
    "# mean = [0.4222796, 0.44544333, 0.44153902]\n",
    "# std = [0.28497052, 0.24810323, 0.2657039]\n",
    "\n",
    "train_transforms, test_transforms = preprochelper.PreprocHelper.getpytorchtransforms(image_net_mean, image_net_std, image_size)\n",
    "ds = dst.Dataset()\n",
    "\n",
    "train_dataset = ds.get_monocular_train_dataset(train_image_data=train_data, train_image_labels=train_label,\n",
    "                                               train_transforms=train_transforms)\n",
    "\n",
    "test_dataset = ds.get_monocular_test_dataset(test_image_labels=test_label, test_image_data=test_data,\n",
    "                                             test_transforms=test_transforms)\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "dataloader = dl.Dataloader(traindataset=train_dataset, testdataset=test_dataset, batch_size=batch_size)\n",
    "train_loader = dataloader.gettraindataloader()\n",
    "test_loader = dataloader.gettestdataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "46ORlmIc6vnA"
   },
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# # use_cuda = torch.cuda.is_available()\n",
    "# # device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "# cnn_model, device = utils.Utils.createMonocularModel()\n",
    "# optimizer = utils.Utils.createoptimizer(cnn_model, lr=0.01, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "# # for name, param in cnn_model.named_parameters():\n",
    "# #     print(name)\n",
    "# #     print(param)\n",
    "\n",
    "# for name, param in cnn_model.named_parameters():\n",
    "# #     print(name)\n",
    "# #     print(param)\n",
    "#     if \"bn1\" in name or \"bn2\" in name:\n",
    "#         i = 0\n",
    "# #         nn.init.constant_(param, 0)        \n",
    "#     elif \"weight\" in name:\n",
    "#         nn.init.kaiming_normal_(param, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "# #     elif \"bias\" in name:\n",
    "# #         nn.init.constant_(param, 0)\n",
    "\n",
    "# last_epoch = 1\n",
    "\n",
    "# # model_path = r'D:\\Development\\TSAI\\EVA\\Git Repo\\EVA\\A15-PartB\\weights\\checkpoint-10.pt'\n",
    "# # if os.path.exists(model_path):\n",
    "# #     print('model loaded')\n",
    "# #     checkpoint, epoch, model_state_dict, optimizer_state_dict, train_losses, train_acc, test_losses, test_acc \\\n",
    "# #         , test_losses, lr_data, class_correct, class_total = utils.Utils.loadmodel(model_path)\n",
    "# #     cnn_model.load_state_dict(model_state_dict)\n",
    "# #     optimizer.load_state_dict(optimizer_state_dict)\n",
    "# #     last_epoch = last_epoch + checkpoint['epoch']\n",
    "\n",
    "# # cnn_model = torchvision.models.resnet18(pretrained=False, num_classes=2).cuda(device)\n",
    "\n",
    "\n",
    "# sample = next(iter(train_loader))\n",
    "\n",
    "# imgs = sample[0][0]\n",
    "\n",
    "# # grid_tensor = torchvision.utils.make_grid(imgs, 2)\n",
    "# # grid_image = grid_tensor.permute(1, 2, 0)\n",
    "\n",
    "# utils.Utils.show(imgs, nrow=4)\n",
    "\n",
    "# train_model = train.TrainModel()\n",
    "# # print(cnn_model)\n",
    "# # print(cnn_model.parameters())\n",
    "# train_model.showmodelsummary(model=cnn_model,input_size=[(4,3,64,64)])\n",
    "# # optimizer = utils.Utils.createoptimizer(cnn_model, lr=0.01, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "# # scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.05, patience=1, \n",
    "#             verbose=True, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "# lr_data = []\n",
    "# class_correct = list(0. for i in range(10))\n",
    "# class_total = list(0. for i in range(10))\n",
    "# epochs = 20\n",
    "\n",
    "# def count_parameters(model):\n",
    "#     return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# print(count_parameters(cnn_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 246
    },
    "colab_type": "code",
    "id": "hXXAg8hbK16u",
    "outputId": "45faab6a-4a85-4846-be9f-5e4e2a29b61e"
   },
   "outputs": [],
   "source": [
    "# from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss, MSELoss, L1Loss\n",
    "# from src.train.customlossfunction import DiceLoss\n",
    "# # loss_fn = BCEWithLogitsLoss()\n",
    "# # loss_fn = L1Loss()\n",
    "# # loss_fn = MSELoss()\n",
    "# loss_fn = DiceLoss()\n",
    "# show_output = True\n",
    "# infer_index = 2\n",
    "# for epoch in range(1, epochs):\n",
    "#     print(\"EPOCH:\", epoch)\n",
    "    \n",
    "#     tr_out = train_model.train_Monocular(cnn_model, device, train_loader, optimizer, epoch, loss_fn, show_output, infer_index)\n",
    "#     ts_out, dice_loss = train_model.test_Monocular(cnn_model, device, test_loader, class_correct, class_total, epoch, lr_data, loss_fn, \n",
    "#                                         show_output, infer_index)\n",
    "    \n",
    "#     from src.utils.utils import Utils\n",
    "\n",
    "#     Utils.show(tr_out.detach().cpu(), nrow=4)\n",
    "#     Utils.show(ts_out.detach().cpu(), nrow=4)\n",
    "    \n",
    "#     scheduler.step(dice_loss)\n",
    "\n",
    "# # train_losses, train_acc = train_model.gettraindata()\n",
    "# # test_losses, test_acc = train_model.gettestdata()\n",
    "# # utils.Utils.savemodel(model=cnn_model, epoch=epochs, path=\"savedmodels/finalmodelwithdata.pt\",\n",
    "# #                       optimizer_state_dict=optimizer.state_dict\n",
    "# #                       , train_losses=train_losses, train_acc=train_acc, test_acc=test_acc,\n",
    "# #                       test_losses=test_losses, lr_data=lr_data, class_correct=class_correct, class_total=class_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# model_save_path = \"savedmodels\" + os.path.sep + \"finalmodelwithdata.pt\"\n",
    "# train_losses, train_acc = train_model.gettraindata()\n",
    "# test_losses, test_acc = train_model.gettestdata()\n",
    "# utils.Utils.savemodel(model=cnn_model, epoch=epochs, path=\"finalmodelwithdata.pt\",\n",
    "#                       optimizer_state_dict=optimizer.state_dict\n",
    "#                       , train_losses=train_losses, train_acc=train_acc, test_acc=test_acc,\n",
    "#                       test_losses=test_losses, lr_data=lr_data, class_correct=class_correct, class_total=class_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "# use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "\n",
    "cnn_model_mask, device = utils.Utils.createMonocularModel()\n",
    "optimizer_mask = utils.Utils.createoptimizer(cnn_model_mask, lr=0.01, momentum=0.9, weight_decay=1e-5) #1e-5\n",
    "scheduler_mask = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_mask, mode='max', factor=0.05, patience=1, \n",
    "            verbose=True, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "cnn_model_depthmask, device = utils.Utils.createDepthModel()\n",
    "optimizer_depthmask = utils.Utils.createoptimizer(cnn_model_depthmask, lr=0.5, momentum=0.9, weight_decay=1e-5) #1e-5\n",
    "scheduler_depthmask = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer_depthmask, mode='max', factor=0.05, patience=1, \n",
    "            verbose=True, threshold=0.01, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)\n",
    "\n",
    "# for name, param in cnn_model.named_parameters():\n",
    "#     print(name)\n",
    "#     print(param)\n",
    "\n",
    "for name, param in cnn_model_mask.named_parameters():\n",
    "#     print(name)\n",
    "#     print(param)\n",
    "    if \"bn1\" in name or \"bn2\" in name or \"double_conv\" in name:\n",
    "        i = 0\n",
    "#         nn.init.constant_(param, 0)        \n",
    "    elif \"weight\" in name:\n",
    "        nn.init.kaiming_normal_(param, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "#     elif \"bias\" in name:\n",
    "#         nn.init.constant_(param, 0)\n",
    "\n",
    "for name, param in cnn_model_depthmask.named_parameters():\n",
    "#     print(name)\n",
    "#     print(param)\n",
    "    if \"bn1\" in name or \"bn2\" in name or \"double_conv\" in name:\n",
    "        i = 0\n",
    "#         nn.init.constant_(param, 0)        \n",
    "    elif \"weight\" in name:\n",
    "        nn.init.kaiming_normal_(param, mode=\"fan_out\", nonlinearity=\"relu\")\n",
    "#     elif \"bias\" in name:\n",
    "#         nn.init.constant_(param, 0)\n",
    "\n",
    "last_epoch = 1\n",
    "\n",
    "# model_path = r'D:\\Development\\TSAI\\EVA\\Git Repo\\EVA\\A15-PartB\\weights\\checkpoint-10.pt'\n",
    "# if os.path.exists(model_path):\n",
    "#     print('model loaded')\n",
    "#     checkpoint, epoch, model_state_dict, optimizer_state_dict, train_losses, train_acc, test_losses, test_acc \\\n",
    "#         , test_losses, lr_data, class_correct, class_total = utils.Utils.loadmodel(model_path)\n",
    "#     cnn_model.load_state_dict(model_state_dict)\n",
    "#     optimizer.load_state_dict(optimizer_state_dict)\n",
    "#     last_epoch = last_epoch + checkpoint['epoch']\n",
    "\n",
    "# cnn_model = torchvision.models.resnet18(pretrained=False, num_classes=2).cuda(device)\n",
    "\n",
    "\n",
    "sample = next(iter(train_loader))\n",
    "\n",
    "imgs = sample[0][0]\n",
    "\n",
    "utils.Utils.show(imgs, nrow=4)\n",
    "\n",
    "train_model = train.TrainModel()\n",
    "\n",
    "train_model.showmodelsummary(model=cnn_model_mask,input_size=[(4,3,64,64)])\n",
    "train_model.showmodelsummary(model=cnn_model_depthmask,input_size=[(4,3,64,64)])\n",
    "\n",
    "# optimizer = utils.Utils.createoptimizer(cnn_model, lr=0.01, momentum=0.9, weight_decay=1e-5)\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.01)\n",
    "\n",
    "\n",
    "\n",
    "lr_data = []\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import CrossEntropyLoss, BCEWithLogitsLoss, MSELoss, L1Loss, BCELoss, SmoothL1Loss\n",
    "from src.train.customlossfunction import DiceLoss\n",
    "# from kornia.losses import SSIM\n",
    "# loss_fn = SSIM(window_size=3,reduction='sum')\n",
    "# loss_fn = BCEWithLogitsLoss()\n",
    "loss_fn_depthmask = SmoothL1Loss()\n",
    "# loss_fn = MSELoss()\n",
    "loss_fn_mask = DiceLoss()\n",
    "# loss_fn = BCELoss(reduction='mean')\n",
    "show_output = True\n",
    "infer_index = 3\n",
    "for epoch in range(1, epochs):\n",
    "    print(\"EPOCH:\", epoch)\n",
    "    \n",
    "    tr_out_m,tr_out_dm = train_model.train_DualLoss(cnn_model_mask,cnn_model_depthmask, \n",
    "                                                    device, train_loader, optimizer_mask,optimizer_depthmask, epoch, \n",
    "                                                    loss_fn_mask,loss_fn_depthmask, show_output)\n",
    "    \n",
    "    ts_out_m, ts_out_dm, ts_acc_m,ts_ac_dm = train_model.test_DualLoss(cnn_model_mask,cnn_model_depthmask,\n",
    "                                                                       device, test_loader, class_correct\n",
    "                                                                      , class_total, epoch, lr_data, loss_fn_mask,\n",
    "                                                                      loss_fn_depthmask,show_output)\n",
    "    \n",
    "    from src.utils.utils import Utils\n",
    "\n",
    "    Utils.show(tr_out_m.detach().cpu(), nrow=8)\n",
    "    Utils.show(ts_out_m.detach().cpu(), nrow=8)\n",
    "    Utils.show(tr_out_dm.detach().cpu(), nrow=8)\n",
    "    Utils.show(ts_out_dm.detach().cpu(), nrow=8)\n",
    "    \n",
    "    scheduler_mask.step(ts_acc)\n",
    "    scheduler_depthmask.step(ts_ac_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_losses_mask, train_acc_mask, test_losses_mask, test_acc_mask, train_losses_depthmask, train_acc_depthmask, test_losses_depthmask, \n",
    "test_acc_depthmask = train_model.gettraintestdatafordualmodels()\n",
    "\n",
    "model_save_path_mask = \"savedmodels\" + os.path.sep + \"finalmodelwithdata-mask.pt\"\n",
    "\n",
    "Utils.savemodel(model=model_mask, epoch=epoch, path=model_save_path_mask,\n",
    "    train_acc=train_acc_mask, optimizer_state_dict=optimizer_mask.state_dict()\n",
    "    , train_losses=train_losses_mask, test_acc=test_acc_mask,\n",
    "    test_losses=test_losses_mask, lr_data=lr_data, class_correct=class_correct,\n",
    "    class_total=class_total)\n",
    "\n",
    "model_save_path_depthmask = \"savedmodels\" + os.path.sep + \"finalmodelwithdata-depthmask.pt\"\n",
    "\n",
    "Utils.savemodel(model=model_depthmask, epoch=epoch, path=model_save_path_depthmask,\n",
    "    train_acc=train_acc_depthmask, optimizer_state_dict=optimizer_depthmask.state_dict()\n",
    "    , train_losses=train_losses_depthmask, test_acc=test_acc_depthmask,\n",
    "    test_losses=test_losses_depthmask, lr_data=lr_data, class_correct=class_correct,\n",
    "    class_total=class_total)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "A12-A.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
